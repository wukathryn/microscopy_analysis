{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687c37ea-f6b6-409b-b885-1b6b4c5e6ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "from aicsimageio import AICSImage\n",
    "from aicsimageio.readers.ome_tiff_reader import OmeTiffReader\n",
    "from aicsimageio.writers import OmeTiffWriter\n",
    "\n",
    "import sys\n",
    "src_path = str(Path.cwd().parent.parent)\n",
    "if src_path not in sys.path:\n",
    "    sys.path.append(src_path)\n",
    "\n",
    "import src.d00_utils.utilities as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3873be64-5038-4936-8508-b977a3053ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_dirpath = Path(input())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b55c852-7e74-408e-8d08-b974268f9ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dirpaths = list(overall_dirpath.rglob('*cellch'))\n",
    "print(len(dirpaths))\n",
    "print(dirpaths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f112961a-0294-405d-905f-352f6e8eb889",
   "metadata": {},
   "outputs": [],
   "source": [
    "well_conditions_csvpath = Path(input())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5762b5b-9808-4d74-83d8-114048411beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions_df = pd.read_csv(well_conditions_csvpath)\n",
    "conditions_df.head()\n",
    "conditions_df = conditions_df[conditions_df['Drug tx'] != 'none']\n",
    "conditions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee882044-2e4a-4823-aca9-4bed48be8bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouping_vars = ['Drug tx', 'cellch', 'Replicate']\n",
    "sample_df = conditions_df.groupby(grouping_vars).sample(n=1)\n",
    "sample_df\n",
    "print(len(sample_df))\n",
    "sample_df['wellID'] = sample_df['Experiment'] + '-' + sample_df['Well']\n",
    "sample_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bcebbdf-a546-4d5f-aa59-5624ae723902",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dirpaths = []\n",
    "\n",
    "# dirpath = None\n",
    "# while dirpath != 'DONE':\n",
    "#     dirpath = input('Dirpath (or type DONE if done):')\n",
    "#     if dirpath == 'DONE':\n",
    "#         break\n",
    "#     else:\n",
    "#         dirpaths.append(Path(dirpath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d7f5b0-99f2-483b-98b3-918a005be9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1 # Number of randomly chosen images to use from each well\n",
    "img_purpose = ['test', 'train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b835625b-f2f2-4ca5-96d3-21068795b772",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate dictionary to hold imgpaths, grouping variables\n",
    "img_list_d = {}\n",
    "for p in img_purpose:\n",
    "    img_list_d[p] = []\n",
    "\n",
    "# Select imagepaths\n",
    "for i, row in sample_df.iterrows():\n",
    "    wellID = row['wellID']\n",
    "    \n",
    "    imgpaths = []\n",
    "    for dirpath in dirpaths:\n",
    "        w_search = '*' + wellID.replace('-', '*') + '*.ome.tif'\n",
    "        imgpaths.extend([path for path in dirpath.glob(w_search)])\n",
    "    \n",
    "    \n",
    "    grouping_vars_str = ', '.join([f'{var}: {row[var]}' for var in grouping_vars])\n",
    "    print(f'{wellID} [{grouping_vars_str}]: {len(imgpaths)} images found')\n",
    "    \n",
    "    num_to_select = n * len(img_purpose)\n",
    "    if len(imgpaths) > num_to_select:\n",
    "        selected_bywell = random.sample(imgpaths, num_to_select)\n",
    "    \n",
    "        for i, p in enumerate(img_purpose):\n",
    "            img_list_d[p].extend(selected_bywell[i:(i + n)])\n",
    "            \n",
    "for i, p in enumerate(img_purpose):\n",
    "    print(f'{p}: {len(img_list_d[p])} images selected')\n",
    "\n",
    "stack_df = pd.DataFrame()\n",
    "stack_df['imgpath'] = np.concatenate([img_list for p, img_list in img_list_d.items()])\n",
    "stack_df['purpose'] = np.concatenate([[p]*len(img_list) for p, img_list in img_list_d.items()])\n",
    "\n",
    "stack_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5824ba-db29-43a4-982d-cfe767d5e46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_train_imgpath = input('Input path for previous training image (if using). Otherwise, type NONE.')\n",
    "\n",
    "if prev_train_imgpath=='NONE':\n",
    "    print('No previous training image.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fffc468-51d2-4a3b-bd6c-1fa46c1ad496",
   "metadata": {},
   "outputs": [],
   "source": [
    "savedir = Path('/Users/kwu2/Library/CloudStorage/GoogleDrive-kwu2@stanford.edu/My Drive/Lab/ImageJ/training_imgs')\n",
    "\n",
    "stack_basename = input(\"Enter basename for stacked image (excluding suffix):\")\n",
    "\n",
    "i = 0\n",
    "savepaths = np.array([savedir / (f'{stack_basename}_{p}_{i}.ome.tif') for p in img_purpose])\n",
    "\n",
    "while savepaths[0].is_file() or savepaths[1].is_file():\n",
    "    i = i+1\n",
    "    savepaths = np.array([savedir / (f'{stack_basename}_{p}_{i}.ome.tif') for p in img_purpose])\n",
    "    \n",
    "for path in savepaths:\n",
    "    print(path.name)\n",
    "    \n",
    "csv_savename = f'{stack_basename}_{i}.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14659508-b232-4c55-abe8-92aed2a6150e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_imgs_to_list(imgpaths, img_list, df, num_tps=3):\n",
    "\n",
    "    for i, imgpath in enumerate(imgpaths):\n",
    "        #img_file = AICSImage(imgpath, reader=OmeTiffReader)\n",
    "        img_file = AICSImage(imgpath)\n",
    "        print(img_file.shape)\n",
    "        img = img_file.data\n",
    "        \n",
    "        if i==0:\n",
    "            physical_pixel_sizes = img_file.physical_pixel_sizes\n",
    "        \n",
    "        if img.shape[0] > 1:\n",
    "            tps = [0, random.randint(1, img.shape[0]-2), img.shape[0]-1]\n",
    "            tps = random.sample(tps, num_tps)\n",
    "            print(f'timepoints: {tps}')\n",
    "            df.loc[df['imgpath']==imgpath, 'timepoints'] = ', '.join([str(tp) for tp in tps])\n",
    "            img_fewtps = np.concatenate([img[tp, np.newaxis, :, :, :, :] for tp in tps], axis=0)\n",
    "            img_list.append(img_fewtps)\n",
    "        else:\n",
    "            img_list.append(img)\n",
    "            df.loc[df['imgpath']==imgpath, 'timepoints'] = str(0)\n",
    "            \n",
    "    return img_list, df, physical_pixel_sizes\n",
    "\n",
    "# Get the smallest y and x dimensions to crop all images to the same size\n",
    "def crop_imgs_to_match_size(img_list):\n",
    "    y_min = None\n",
    "    x_min = None\n",
    "\n",
    "    for img in img_list:\n",
    "\n",
    "        if y_min is None:\n",
    "            y_min = img.shape[3]\n",
    "        else:\n",
    "            y_min = np.minimum(img.shape[3], y_min)\n",
    "\n",
    "        if x_min is None:\n",
    "            x_min = img.shape[4]\n",
    "        else:\n",
    "            x_min = np.minimum(img.shape[4], x_min)\n",
    "\n",
    "    imgs_crop = [img[:, :, :, :y_min, :x_min] for img in img_list]\n",
    "    return imgs_crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46033035-9043-46e2-a392-e15930f44db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, p in enumerate(img_list_d.keys()):\n",
    "    print(p)\n",
    "    img_list = []\n",
    "    imgpaths_subset = img_list_d[p]\n",
    "    \n",
    "    # Only append previous training images to training image stack\n",
    "    if p == 'test':\n",
    "        if prev_train_imgpath!='NONE':\n",
    "            prev_train_imgpath = Path(prev_train_imgpath)\n",
    "            prev_img_file = AICSImage(prev_train_imgpath, reader=OmeTiffReader)\n",
    "            print(prev_img_file.shape)\n",
    "            prev_img = prev_img_file.data\n",
    "            img_list.append(prev_img)\n",
    "            \n",
    "    img_list, stack_df, physical_pixel_sizes = add_imgs_to_list(imgpaths_subset, img_list, stack_df, num_tps=2)\n",
    "    img_list = crop_imgs_to_match_size(img_list)\n",
    "    img_stacked = np.concatenate(img_list, axis=0)\n",
    "    ome_metadata = utils.construct_ome_metadata(img_stacked, physical_pixel_sizes)\n",
    "    \n",
    "    OmeTiffWriter.save(img_stacked, savepaths[i], ome_xml=ome_metadata)\n",
    "    stack_df.to_csv(savedir/csv_savename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a41512-a820-40c6-b36a-ff9c01cdad5c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
