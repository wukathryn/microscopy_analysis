{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687c37ea-f6b6-409b-b885-1b6b4c5e6ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "from aicsimageio import AICSImage\n",
    "from aicsimageio.readers.ome_tiff_reader import OmeTiffReader\n",
    "from aicsimageio.writers import OmeTiffWriter\n",
    "\n",
    "import sys\n",
    "src_path = str(Path.cwd().parent.parent)\n",
    "if src_path not in sys.path:\n",
    "    sys.path.append(src_path)\n",
    "\n",
    "import src.d00_utils.utilities as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33551fe-79f0-444b-8bc7-93915c64abe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "multiexp_dir = Path(input())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3a598a-fc15-4272-9787-f6059c7cdf73",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = Path(input())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5cd9e81-0435-4272-84b4-af64242c0f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_savepath = save_dir / 'combined_well_conditions_modified.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6577c5-aaf2-43c5-bb5b-9433cdd79bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "exps = ['CE023', 'CE025', 'CE027']\n",
    "\n",
    "exp_dir = [d for d in multiexp_dir.iterdir() if any(d.match(e) for e in exps)]\n",
    "print(len(exp_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f112961a-0294-405d-905f-352f6e8eb889",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get paths for csvs with condition info\n",
    "conditions_dirpaths = []\n",
    "\n",
    "for e in exp_dir:\n",
    "    exp_conditions = list(e.glob('*well_conditions_modified*'))\n",
    "    conditions_dirpaths.extend(exp_conditions)\n",
    "    if len(exp_conditions) == 0:\n",
    "        [conditions_dirpaths.extend(list(d.glob('*well_conditions_modified*'))) for d in e.iterdir() if d.is_dir()]\n",
    "\n",
    "print(len(conditions_dirpaths))\n",
    "print(conditions_dirpaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27c53c7-d094-4d2e-8b1f-6603c4e75c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_dfs = [pd.read_csv(p) for p in conditions_dirpaths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b5f5d9-c946-4c3b-8856-aac8c8c03a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(list_dfs)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c45a17-6116-4bee-85ea-6bd509853dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['wellID'] = df['Experiment'] + '-' + df['Ibidi'] + '-' + df['Well']\n",
    "df.to_csv(csv_savepath, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3fc43c-f756-46a5-bb10-a95a18eaed42",
   "metadata": {},
   "outputs": [],
   "source": [
    "#conditions = [(exps == 'CE027') & (ibidis == 'I1')]\n",
    "CE027_rep1 = ['I1', 'I2', 'I3', 'I4']\n",
    "CE027_rep2 = ['I5', 'I6', 'I7', 'I8']\n",
    "conditions = [df['Experiment']=='CE023',\n",
    "              df['Experiment']=='CE025',\n",
    "              (df['Experiment']=='CE027') & (df['Ibidi'].isin(CE027_rep1)),\n",
    "              (df['Experiment']=='CE027') & (df['Ibidi'].isin(CE027_rep2))]\n",
    "\n",
    "choices = [1, 2, 3, 4]\n",
    "df['Replicate'] = np.select(conditions, choices, -1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d97bc39-d538-40ee-90eb-f0177b8030e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Virus_old'] = df['Virus']\n",
    "virus_old = np.unique(df['Virus'].astype(str))\n",
    "print(virus_old)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57f76bf-5d89-4beb-8619-5d9ac7fe07b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrections = ['218', '218 + 424', '218 + 281', '218 + 424', '281', '281 + 351', '281 + 351', '283', '218 + 283', '281 + 351', 'nan']\n",
    "\n",
    "print(np.unique(corrections))\n",
    "\n",
    "\n",
    "for old, new in zip(virus_old, corrections):\n",
    "    print(f'{old}: {new}')\n",
    "conditions = [df['Virus_old']==e for e in virus_old]\n",
    "df['Virus'] = np.select(conditions, corrections, 'nan')\n",
    "df.to_csv(csv_savepath, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5762b5b-9808-4d74-83d8-114048411beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions_df = df\n",
    "#conditions_df = pd.read_csv(well_conditions_csvpath)\n",
    "conditions_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee882044-2e4a-4823-aca9-4bed48be8bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions_df = conditions_df[conditions_df['Exp or ctrl']=='Exp']\n",
    "grouping_vars = ['Virus', 'Replicate', 'DIV']\n",
    "sample_df = conditions_df.groupby(grouping_vars).sample(n=1)\n",
    "sample_df\n",
    "print(len(sample_df))\n",
    "sample_df['wellID'] = sample_df['Experiment'] + '-' + sample_df['Well']\n",
    "sample_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bcebbdf-a546-4d5f-aa59-5624ae723902",
   "metadata": {},
   "outputs": [],
   "source": [
    "dirpaths = []\n",
    "\n",
    "dirpath = None\n",
    "while dirpath != 'DONE':\n",
    "    dirpath = input('Dirpath (or type DONE if done):')\n",
    "    if dirpath == 'DONE':\n",
    "        break\n",
    "    else:\n",
    "        dirpaths.append(Path(dirpath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7561c6-9409-464a-96ae-3b736a80bb0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dirpaths = []\n",
    "# for d in exp_dir:\n",
    "#     print(d)\n",
    "#     dirpaths.extend(d.glob('**'))\n",
    "\n",
    "\n",
    "dirpaths = [d for d in dirpaths if 'caaxch' in d.name]\n",
    "print(len(dirpaths))\n",
    "print(dirpaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d7f5b0-99f2-483b-98b3-918a005be9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1 # Number of randomly chosen images to use from each well\n",
    "img_purpose = ['test', 'train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b835625b-f2f2-4ca5-96d3-21068795b772",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate dictionary to hold imgpaths, grouping variables\n",
    "img_list_d = {}\n",
    "for p in img_purpose:\n",
    "    img_list_d[p] = []\n",
    "\n",
    "# Select imagepaths\n",
    "for i, row in sample_df.iterrows():\n",
    "    wellID = row['wellID']\n",
    "    \n",
    "    imgpaths = []\n",
    "    for dirpath in dirpaths:\n",
    "        w_search = '*' + wellID.replace('-', '*') + '*.ome.tif'\n",
    "        imgpaths.extend([path for path in dirpath.glob(w_search)])\n",
    "    \n",
    "    \n",
    "    grouping_vars_str = ', '.join([f'{var}: {row[var]}' for var in grouping_vars])\n",
    "    print(f'{wellID} [{grouping_vars_str}]: {len(imgpaths)} images found')\n",
    "    \n",
    "    num_to_select = n * len(img_purpose)\n",
    "    if len(imgpaths) > num_to_select:\n",
    "        selected_bywell = random.sample(imgpaths, num_to_select)\n",
    "    \n",
    "        for i, p in enumerate(img_purpose):\n",
    "            img_list_d[p].extend(selected_bywell[i:(i + n)])\n",
    "            \n",
    "for i, p in enumerate(img_purpose):\n",
    "    print(f'{p}: {len(img_list_d[p])} images selected')\n",
    "\n",
    "stack_df = pd.DataFrame()\n",
    "stack_df['imgpath'] = np.concatenate([img_list for p, img_list in img_list_d.items()])\n",
    "stack_df['purpose'] = np.concatenate([[p]*len(img_list) for p, img_list in img_list_d.items()])\n",
    "\n",
    "stack_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5824ba-db29-43a4-982d-cfe767d5e46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_train_imgpath = input('Input path for previous training image (if using). Otherwise, type NONE.')\n",
    "\n",
    "if prev_train_imgpath=='NONE':\n",
    "    print('No previous training image.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fffc468-51d2-4a3b-bd6c-1fa46c1ad496",
   "metadata": {},
   "outputs": [],
   "source": [
    "savedir = Path('/Users/kwu2/Library/CloudStorage/GoogleDrive-kwu2@stanford.edu/My Drive/Lab/ImageJ/training_imgs')\n",
    "\n",
    "stack_basename = input(\"Enter basename for stacked image (excluding suffix):\")\n",
    "\n",
    "i = 0\n",
    "savepaths = np.array([savedir / (f'{stack_basename}_{p}_{i}.ome.tif') for p in img_purpose])\n",
    "\n",
    "while savepaths[0].is_file() or savepaths[1].is_file():\n",
    "    i = i+1\n",
    "    savepaths = np.array([savedir / (f'{stack_basename}_{p}_{i}.ome.tif') for p in img_purpose])\n",
    "    \n",
    "for path in savepaths:\n",
    "    print(path.name)\n",
    "    \n",
    "csv_savename = f'{stack_basename}_{i}.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14659508-b232-4c55-abe8-92aed2a6150e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_imgs_to_list(imgpaths, img_list, df, num_tps=3):\n",
    "\n",
    "    for i, imgpath in enumerate(imgpaths):\n",
    "        img_file = AICSImage(imgpath, reader=OmeTiffReader)\n",
    "        img = img_file.data\n",
    "        \n",
    "        if i==0:\n",
    "            physical_pixel_sizes = img_file.physical_pixel_sizes\n",
    "        \n",
    "        if img.shape[0] > 1:\n",
    "            tps = [0, random.randint(1, img.shape[0]-2), img.shape[0]-1]\n",
    "            tps = random.sample(tps, num_tps)\n",
    "            print(f'timepoints: {tps}')\n",
    "            df.loc[df['imgpath']==imgpath, 'timepoints'] = ', '.join([str(tp) for tp in tps])\n",
    "            img_fewtps = np.concatenate([img[tp, np.newaxis, :, :, :, :] for tp in tps], axis=0)\n",
    "            img_list.append(img_fewtps)\n",
    "        else:\n",
    "            img_list.append(img)\n",
    "            df.loc[df['imgpath']==imgpath, 'timepoints'] = str(0)\n",
    "            \n",
    "    return img_list, df, physical_pixel_sizes\n",
    "\n",
    "# Get the smallest y and x dimensions to crop all images to the same size\n",
    "def crop_imgs_to_match_size(img_list):\n",
    "    y_min = None\n",
    "    x_min = None\n",
    "\n",
    "    for img in img_list:\n",
    "\n",
    "        if y_min is None:\n",
    "            y_min = img.shape[3]\n",
    "        else:\n",
    "            y_min = np.minimum(img.shape[3], y_min)\n",
    "\n",
    "        if x_min is None:\n",
    "            x_min = img.shape[4]\n",
    "        else:\n",
    "            x_min = np.minimum(img.shape[4], x_min)\n",
    "\n",
    "    imgs_crop = [img[:, :, :, :y_min, :x_min] for img in img_list]\n",
    "    return imgs_crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46033035-9043-46e2-a392-e15930f44db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, p in enumerate(img_list_d.keys()):\n",
    "    img_list = []\n",
    "    imgpaths_subset = img_list_d[p]\n",
    "    \n",
    "    # Only append previous training images to training image stack\n",
    "    if p == 'test':\n",
    "        if prev_train_imgpath!='NONE':\n",
    "            prev_train_imgpath = Path(prev_train_imgpath)\n",
    "            prev_img_file = AICSImage(prev_train_imgpath, reader=OmeTiffReader)\n",
    "            prev_img = prev_img_file.data\n",
    "            img_list.append(prev_img)\n",
    "            \n",
    "    img_list, stack_df, physical_pixel_sizes = add_imgs_to_list(imgpaths_subset, img_list, stack_df, num_tps=2)\n",
    "    img_list = crop_imgs_to_match_size(img_list)\n",
    "    img_stacked = np.concatenate(img_list, axis=0)\n",
    "    ome_metadata = utils.construct_ome_metadata(img_stacked, physical_pixel_sizes)\n",
    "    \n",
    "    OmeTiffWriter.save(img_stacked, savepaths[i], ome_xml=ome_metadata)\n",
    "    stack_df.to_csv(savedir/csv_savename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a41512-a820-40c6-b36a-ff9c01cdad5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb742077-ddcc-4690-a1f8-f4af34a4e334",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
